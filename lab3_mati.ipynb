{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b86029-f257-430b-91d3-cf4c2f3165ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases real =         label\n",
      "13399    1.0\n",
      "11796    1.0\n",
      "12736    1.0\n",
      "13518    1.0\n",
      "16113    1.0\n",
      "...      ...\n",
      "1316     0.0\n",
      "3740     0.0\n",
      "11676    1.0\n",
      "353      0.0\n",
      "17345    1.0\n",
      "\n",
      "[7146 rows x 1 columns]\n",
      "Clases pred =  [1. 1. 1. ... 1. 1. 1.]\n",
      "El accuracy de la fase de test es:  0.5737475510775258\n",
      "El accuracy de la fase de entrenamiento es:  0.5842119996267612\n"
     ]
    }
   ],
   "source": [
    "#ejercicio 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df = pd.read_excel ('uw-vehicle-1.xlsx')\n",
    "X = np.transpose(np.transpose(df)[1:17])\n",
    "y = np.transpose(np.transpose(df)[17:18])\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=11)\n",
    "\n",
    "clf = SVC() \n",
    "clf.fit(X_train, np.ravel(y_train)) \n",
    "y_test_pred = clf.predict(X_test) \n",
    " \n",
    "print('Clases real = ', y_test) \n",
    "print('Clases pred = ', y_test_pred) \n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    " \n",
    "accuracy_test = accuracy_score(y_test, y_test_pred) \n",
    "print('El accuracy de la fase de test es: ', accuracy_test) \n",
    " \n",
    "y_pred_train = clf.predict(X_train) \n",
    "accuracy_train = accuracy_score(y_train, y_pred_train) \n",
    "print('El accuracy de la fase de entrenamiento es: ', accuracy_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec654a6-12ba-450b-80f7-56f93da180d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El recall en la fase de test es:  0.983030303030303\n",
      "El precision en la fase de test es:  0.5767316171241644\n"
     ]
    }
   ],
   "source": [
    "#ejercicio 2\n",
    "#¿Por qu´e resultan los valores de exactitudobtenidos en el Ejercicio 1? Fundamentar la respuesta apoy´andose en las metricas\n",
    "#de exhaustividad (recall) y precision calculadas para los datos de test. ¿Cual seria la exactitud del clasificador si \n",
    "#siempre predijera que hay una falla en todas las observaciones?\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "print('El recall en la fase de test es: ', recall)\n",
    "\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "print('El precision en la fase de test es: ', precision)\n",
    "\n",
    "# Observando el alto valor del recall pero baja precisión, podemos entender que el modelo tiende a predecir casi siempre\n",
    "# que existen fallas, teniendo un 57.6% de probabilidad que esta falla sea verdadera, por lo tanto con esto se puede justificar\n",
    "# el bajo valor de exactitud obtenido en el ejercicio 1\n",
    "#La exactitud seria de 100%, ya que esta prediciendo que "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac5d4e78-526d-44bb-9244-10ce479d377e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           params  rank_test_score\n",
      "0  {'C': 0.1, 'kernel': 'linear'}                1\n",
      "1     {'C': 0.1, 'kernel': 'rbf'}                4\n",
      "2    {'C': 1, 'kernel': 'linear'}                3\n",
      "3       {'C': 1, 'kernel': 'rbf'}                4\n",
      "4   {'C': 10, 'kernel': 'linear'}                2\n",
      "5      {'C': 10, 'kernel': 'rbf'}                6\n"
     ]
    }
   ],
   "source": [
    "#ejercicio 3\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[0.1, 1, 10]} \n",
    "clf = SVC() \n",
    "xclf = GridSearchCV(clf, parameters, scoring='accuracy', cv=5) \n",
    "xclf.fit(X_train, np.ravel(y_train)) \n",
    "sorted(xclf.cv_results_.keys()) \n",
    " \n",
    "mydict = {'params':xclf.cv_results_['params'], 'rank_test_score':xclf.cv_results_['rank_test_score']}\n",
    "mydata = pd.DataFrame.from_dict(mydict) \n",
    "print(mydata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ed61977-9f31-4346-afef-e555d5bc4d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en la fase de test es:  0.7626644276518332\n",
      "El recall en la fase de test es:  0.8945454545454545\n",
      "El precision en la fase de test es:  0.7453039789941426\n"
     ]
    }
   ],
   "source": [
    "clf_grid = SVC(C=0.1, kernel='linear')\n",
    "clf_grid.fit(X_train, np.ravel(y_train))\n",
    "y_test_predict = clf_grid.predict(X_test)\n",
    "accuracy_grid = accuracy_score(y_test, y_test_predict)\n",
    "print('El accuracy en la fase de test es: ', accuracy_grid)\n",
    "\n",
    "recall_grid = recall_score(y_test, y_test_predict)\n",
    "print('El recall en la fase de test es: ', recall_grid)\n",
    "\n",
    "precision_grid = precision_score(y_test, y_test_predict)\n",
    "print('El precision en la fase de test es: ', precision_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e04d3d-9fb6-4d5e-a739-92540e4a1d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases real =         label\n",
      "13399    1.0\n",
      "11796    1.0\n",
      "12736    1.0\n",
      "13518    1.0\n",
      "16113    1.0\n",
      "...      ...\n",
      "1316     0.0\n",
      "3740     0.0\n",
      "11676    1.0\n",
      "353      0.0\n",
      "17345    1.0\n",
      "\n",
      "[7146 rows x 1 columns]\n",
      "Clases pred =  [1. 1. 1. ... 1. 0. 1.]\n",
      "El accuracy de la fase de test es:  0.9144976210467395\n",
      "El accuracy de la fase de entrenamiento es:  0.9242325277596343\n",
      "El recall en la fase de test es:  0.9808484848484849\n",
      "El precision en la fase de test es:  0.8837920489296636\n"
     ]
    }
   ],
   "source": [
    "#ejercicio 4\n",
    "df2 = pd.read_excel ('uw-vehicle-norm-1.xlsx')\n",
    "X2 = np.transpose(np.transpose(df2)[1:17])\n",
    "y2 = np.transpose(np.transpose(df2)[17:18])\n",
    " \n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.4, random_state=11)\n",
    "\n",
    "clf2 = SVC() \n",
    "clf2.fit(X_train2, np.ravel(y_train2)) \n",
    "y_test_pred2 = clf2.predict(X_test2) \n",
    " \n",
    "print('Clases real = ', y_test2) \n",
    "print('Clases pred = ', y_test_pred2) \n",
    "\n",
    " \n",
    "accuracy_test2 = accuracy_score(y_test2, y_test_pred2) \n",
    "print('El accuracy de la fase de test es: ', accuracy_test2) \n",
    " \n",
    "y_pred_train2 = clf2.predict(X_train2) \n",
    "accuracy_train2 = accuracy_score(y_train2, y_pred_train2) \n",
    "print('El accuracy de la fase de entrenamiento es: ', accuracy_train2)\n",
    "\n",
    "recall2 = recall_score(y_test2, y_test_pred2)\n",
    "print('El recall en la fase de test es: ', recall2)\n",
    "\n",
    "precision2 = precision_score(y_test2, y_test_pred2)\n",
    "print('El precision en la fase de test es: ', precision2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2889ed18-11b9-43cc-b4ad-752b981ccbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           params  rank_test_score\n",
      "0  {'C': 0.1, 'kernel': 'linear'}                6\n",
      "1     {'C': 0.1, 'kernel': 'rbf'}                3\n",
      "2    {'C': 1, 'kernel': 'linear'}                5\n",
      "3       {'C': 1, 'kernel': 'rbf'}                2\n",
      "4   {'C': 10, 'kernel': 'linear'}                4\n",
      "5      {'C': 10, 'kernel': 'rbf'}                1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[0.1, 1, 10]} \n",
    "clf2 = SVC() \n",
    "xclf2 = GridSearchCV(clf2, parameters, scoring='accuracy', cv=5) \n",
    "xclf2.fit(X_train2, np.ravel(y_train2)) \n",
    "sorted(xclf2.cv_results_.keys()) \n",
    " \n",
    "mydict2 = {'params':xclf2.cv_results_['params'], 'rank_test_score':xclf2.cv_results_['rank_test_score']}\n",
    "mydata2 = pd.DataFrame.from_dict(mydict2) \n",
    "print(mydata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b6c2fb2-2ef6-4206-bdcd-b5ef2d683cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en la fase de test es:  0.9451441365799048\n",
      "El recall en la fase de test es:  0.9798787878787879\n",
      "El precision en la fase de test es:  0.9289818432544242\n"
     ]
    }
   ],
   "source": [
    "clf2_grid = SVC(C=10, kernel='rbf')\n",
    "clf2_grid.fit(X_train2, np.ravel(y_train2))\n",
    "y_test_predict2 = clf2_grid.predict(X_test2)\n",
    "accuracy2_grid = accuracy_score(y_test2, y_test_predict2)\n",
    "print('El accuracy en la fase de test es: ', accuracy2_grid)\n",
    "\n",
    "recall2_grid = recall_score(y_test2, y_test_predict2)\n",
    "print('El recall en la fase de test es: ', recall2_grid)\n",
    "\n",
    "precision2_grid = precision_score(y_test2, y_test_predict2)\n",
    "print('El precision en la fase de test es: ', precision2_grid)\n",
    "\n",
    "# ¿Como influye la normalizacion de atributos en el desempeño del clasificador?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2633d5f4-554d-4edf-a386-e81ae71a2835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09953278, 0.08422801, 0.08092701, 0.08149419, 0.05852259,\n",
       "       0.05883073, 0.19457612, 0.07080037, 0.0659992 , 0.05609133,\n",
       "       0.01126843, 0.0120605 , 0.01072009, 0.01854741, 0.01284879,\n",
       "       0.08355245])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ejercicio 5\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=100,random_state=11)\n",
    "forest.fit(X_train2,np.ravel(y_train2))\n",
    "forest.feature_importances_\n",
    "#Se eligen los 2 atributos con valor mas cercano a 0, ya que estan basado en la impureza gini, y estos son los atributos \n",
    "# 11 y 13 que corresponden a a_x y a_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2ad9262-d016-4b21-bcd2-dd0e1579bb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases real =         label\n",
      "13399    1.0\n",
      "11796    1.0\n",
      "12736    1.0\n",
      "13518    1.0\n",
      "16113    1.0\n",
      "...      ...\n",
      "1316     0.0\n",
      "3740     0.0\n",
      "11676    1.0\n",
      "353      0.0\n",
      "17345    1.0\n",
      "\n",
      "[7146 rows x 1 columns]\n",
      "Clases pred =  [1. 1. 1. ... 1. 1. 1.]\n",
      "El accuracy de la fase de test es:  0.5785054575986566\n",
      "El accuracy de la fase de entrenamiento es:  0.5897172716245218\n",
      "El recall en la fase de test es:  0.9924848484848485\n",
      "El precision en la fase de test es:  0.5786572438162544\n"
     ]
    }
   ],
   "source": [
    "X_atrib = np.array(df2[['a_x','a_z']])\n",
    "y_atrib = np.transpose(np.transpose(df2)[17:18])\n",
    "\n",
    "X_train_atrib, X_test_atrib, y_train_atrib, y_test_atrib = train_test_split(X_atrib, y_atrib, test_size=0.4, random_state=11)\n",
    "\n",
    "clf_atrib = SVC() \n",
    "clf_atrib.fit(X_train_atrib, np.ravel(y_train_atrib)) \n",
    "y_test_pred_atrib = clf_atrib.predict(X_test_atrib) \n",
    " \n",
    "print('Clases real = ', y_test_atrib) \n",
    "print('Clases pred = ', y_test_pred_atrib) \n",
    "\n",
    " \n",
    "accuracy_test_atrib = accuracy_score(y_test_atrib, y_test_pred_atrib) \n",
    "print('El accuracy de la fase de test es: ', accuracy_test_atrib) \n",
    " \n",
    "y_pred_train_atrib = clf_atrib.predict(X_train_atrib) \n",
    "accuracy_train_atrib = accuracy_score(y_train_atrib, y_pred_train_atrib) \n",
    "print('El accuracy de la fase de entrenamiento es: ', accuracy_train_atrib)\n",
    "\n",
    "recall_atrib = recall_score(y_test_atrib, y_test_pred_atrib)\n",
    "print('El recall en la fase de test es: ', recall_atrib)\n",
    "\n",
    "precision_atrib = precision_score(y_test_atrib, y_test_pred_atrib)\n",
    "print('El precision en la fase de test es: ', precision_atrib)\n",
    "\n",
    "#¿Era esperable el resultado obtenido al considerar solo dos de los atributos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8685f0a-ca5a-490a-a4de-50c443df0c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
